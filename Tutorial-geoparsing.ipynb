{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YrOKr9pwkxJw"
   },
   "source": [
    "# NLP for historical texts\n",
    "\n",
    "This notebook is proposed by [L. Moncla](https://ludovicmoncla.github.io/) and [K. McDonough](https://www.turing.ac.uk/people/researchers/katherine-mcdonough) as part of the [Sunoikisis Digital Classics](https://github.com/SunoikisisDC/SunoikisisDC-2021-2022/wiki/SunoikisisDC-Summer-2022-Session-9) Summer course on NLP for historical texts (Session 9).\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/ludovicmoncla/SunoikisisDC-Summer2022-Session9/blob/main/Tutorial-geoparsing.ipynb)\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/ludovicmoncla/SunoikisisDC-Summer2022-Session9/main?filepath=Tutorial-geoparsing.ipynb)\n",
    "\n",
    "\n",
    "## 1. Overview\n",
    "\n",
    "In this tutorial, we'll learn about a few different things:\n",
    "\n",
    "\n",
    "- How to load a dataset from the `Perdido` library as a Python dataframe (articles from Diderot and d'Alembert's *Encyclopédie*)\n",
    "- Use Python dataframe for simple data analysis\n",
    "- How to use the `Perdido Geoparser` library for geoparsing French texts\n",
    "- Display geotagging results\n",
    "- Map geocoding results\n",
    "- Compare the NER results with `spaCy` and `Stanza` (python libraries)\n",
    "- Reflect on the limits of geoparsing historical French (and multilingual) texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5gi1PFqtkxJy"
   },
   "source": [
    "## 2. Introduction\n",
    "\n",
    "Geoparsing (also known as toponym resolution) refers to the process of extracting place names from text and assigning geographic coordinates to them.\n",
    "This involves two main tasks: geotagging and geocoding.\n",
    "Geotagging consists to identify spans of text referring to place names while geocoding consists to find unambiguous geographic coordinates.\n",
    "\n",
    "Geographic text analysis research in the digital humanities has focused on projects analyzing modern English-language corpora. \n",
    "In this tutorial we propose to highlight the difficulties of extracting and mapping geographical information from historical French texts.\n",
    "As we'll see in the following, in addition to the problem of language when it comes to historical documents, the early-modern period lacks temporally appropriate gazetteers.\n",
    "\n",
    "> McDonough, K., Moncla, L., & van de Camp, M. (2019). Named entity recognition goes to old regime France: geographic text analysis for early modern French corpora. International Journal of Geographical Information Science, 33, 2498–2522.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 The Perdido Geoparser python library\n",
    "\n",
    "[Perdido](https://github.com/ludovicmoncla/perdido) is a python text geoparser. It provides NLP and GIS methods for geoparsing French texts.\n",
    "It has initially been developed as a REST API for extracting and retrieving displacements from French hiking descriptions, under the framework of the [PERDIDO](http://erig.univ-pau.fr/PERDIDO/) and [ANR Choucas](http://choucas.ign.fr) projects.\n",
    "\n",
    "More recently, as part of the [GEODE project](https://geode-project.github.io) we have developed a custom version for historical documents and more specifically for the Encyclopédie.\n",
    "\n",
    "\n",
    "In this tutorial we'll see how to use the `Perdido` python library for geoparsing French texts. \n",
    "We will apply geoparsing on volume 7 of Encyclopedie corpus version released by the [ARTFL project](https://encyclopedie.uchicago.edu/) and we'll show the limits of geotagging and geocoding historical documents.\n",
    "\n",
    "### 2.2 Acknowledgement\n",
    "\n",
    "Data courtesy the [ARTFL Encyclopédie Project](https://artfl-project.uchicago.edu/), University of Chicago.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting up the environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Install python packages\n",
    "\n",
    "* If you configured your conda environment using the `requirements.txt` file, you can skip this step and go to the `Import` section.\n",
    "* If you configured your conda environment using the `environment.yml` file or if you use a Google Colab environment, you need to install `perdido` using `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: perdido in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (0.1.21)\n",
      "Requirement already satisfied: spacy>=3.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from perdido) (3.3.1)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from perdido) (2.28.0)\n",
      "Requirement already satisfied: gpxpy in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from perdido) (1.5.0)\n",
      "Requirement already satisfied: lxml in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from perdido) (4.9.0)\n",
      "Requirement already satisfied: geojson in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from perdido) (2.5.0)\n",
      "Requirement already satisfied: folium in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from perdido) (0.12.1.post1)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from perdido) (1.4.2)\n",
      "Requirement already satisfied: jupyter in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from perdido) (1.0.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (3.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (4.64.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (1.22.4)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (3.1.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (0.7.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (1.0.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (1.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (8.0.17)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (62.6.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (2.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (0.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (21.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from spacy>=3.3.0->perdido) (0.6.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from requests->perdido) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from requests->perdido) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from requests->perdido) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from requests->perdido) (2.0.12)\n",
      "Requirement already satisfied: branca>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from folium->perdido) (0.5.0)\n",
      "Requirement already satisfied: qtconsole in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from jupyter->perdido) (5.3.1)\n",
      "Requirement already satisfied: notebook in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from jupyter->perdido) (6.4.12)\n",
      "Requirement already satisfied: nbconvert in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from jupyter->perdido) (6.5.0)\n",
      "Requirement already satisfied: ipykernel in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from jupyter->perdido) (6.15.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from jupyter->perdido) (7.7.0)\n",
      "Requirement already satisfied: jupyter-console in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from jupyter->perdido) (6.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from pandas->perdido) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from pandas->perdido) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from jinja2->spacy>=3.3.0->perdido) (2.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from packaging>=20.0->spacy>=3.3.0->perdido) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from pathy>=0.3.5->spacy>=3.3.0->perdido) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy>=3.3.0->perdido) (4.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->perdido) (1.16.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy>=3.3.0->perdido) (8.1.3)\n",
      "Requirement already satisfied: appnope in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipykernel->jupyter->perdido) (0.1.3)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipykernel->jupyter->perdido) (6.1)\n",
      "Requirement already satisfied: psutil in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipykernel->jupyter->perdido) (5.9.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipykernel->jupyter->perdido) (23.1.0)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipykernel->jupyter->perdido) (5.3.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipykernel->jupyter->perdido) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipykernel->jupyter->perdido) (1.6.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipykernel->jupyter->perdido) (7.3.4)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipykernel->jupyter->perdido) (8.4.0)\n",
      "Requirement already satisfied: nest-asyncio in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipykernel->jupyter->perdido) (1.5.5)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipywidgets->jupyter->perdido) (5.4.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipywidgets->jupyter->perdido) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipywidgets->jupyter->perdido) (3.6.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipywidgets->jupyter->perdido) (1.1.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from jupyter-console->jupyter->perdido) (3.0.29)\n",
      "Requirement already satisfied: pygments in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from jupyter-console->jupyter->perdido) (2.12.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from nbconvert->jupyter->perdido) (0.2.2)\n",
      "Requirement already satisfied: bleach in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from nbconvert->jupyter->perdido) (5.0.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from nbconvert->jupyter->perdido) (0.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from nbconvert->jupyter->perdido) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from nbconvert->jupyter->perdido) (1.5.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from nbconvert->jupyter->perdido) (0.6.4)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from nbconvert->jupyter->perdido) (4.10.0)\n",
      "Requirement already satisfied: defusedxml in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from nbconvert->jupyter->perdido) (0.7.1)\n",
      "Requirement already satisfied: tinycss2 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from nbconvert->jupyter->perdido) (1.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from nbconvert->jupyter->perdido) (4.11.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from notebook->jupyter->perdido) (21.3.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from notebook->jupyter->perdido) (0.15.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from notebook->jupyter->perdido) (0.14.1)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from notebook->jupyter->perdido) (1.8.0)\n",
      "Requirement already satisfied: qtpy>=2.0.1 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from qtconsole->jupyter->perdido) (2.1.0)\n",
      "Requirement already satisfied: decorator in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->perdido) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->perdido) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->perdido) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->perdido) (0.18.1)\n",
      "Requirement already satisfied: backcall in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->perdido) (0.2.0)\n",
      "Requirement already satisfied: stack-data in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->perdido) (0.3.0)\n",
      "Requirement already satisfied: fastjsonschema in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->perdido) (2.15.3)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->perdido) (4.6.0)\n",
      "Requirement already satisfied: wcwidth in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->perdido) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from terminado>=0.8.3->notebook->jupyter->perdido) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from argon2-cffi->notebook->jupyter->perdido) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from beautifulsoup4->nbconvert->jupyter->perdido) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from bleach->nbconvert->jupyter->perdido) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->perdido) (0.8.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->perdido) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->perdido) (0.18.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->perdido) (1.15.0)\n",
      "Requirement already satisfied: asttokens in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->perdido) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->perdido) (0.2.2)\n",
      "Requirement already satisfied: executing in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->perdido) (0.8.3)\n",
      "Requirement already satisfied: pycparser in /opt/homebrew/Caskroom/miniforge/base/envs/sunoikisis-py39/lib/python3.9/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->perdido) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade perdido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Then, if you already configured your conda environment, either with conda or pip (see readme file) you can skip the next cell.\n",
    "* If you're running this notebook from Google Colab, you need to run the next cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Import the libraries\n",
    "\n",
    "First, we will load some specific libraries from `Perdido` that we will use in this notebook. Next, we import some tools that will help us parse and visualize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perdido.geoparser import Geoparser\n",
    "from perdido.datasets import load_edda_artfl, load_edda_perdido\n",
    "\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b9ZN6YgcnxdK"
   },
   "source": [
    "\n",
    "## 4. Getting started\n",
    "\n",
    "In this notebook, we'll test out some basic queries of the *Encyclopédie* articles from volume 7 (H - Itzehoa, published in 1765). You can learn more about the other volumes [here](https://encyclopedie.uchicago.edu/node/102).\n",
    "\n",
    "\n",
    "### 4.1 Loading the ARTFL *Encyclopédie* dataset\n",
    "\n",
    "First, we load the data. You can view this sample dataset at under the 'Data' directory [here](https://github.com/ludovicmoncla/SunoikisisDC-Summer2022-Session9).\n",
    "\n",
    "The next cell loads the data, defines the data as `dataset`, and shows you the top 5 records (`head`). The data has been saved as a dataframe.\n",
    "\n",
    "***define dataframe, explain (briefly) how it parses the TEI-XML***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_edda_artfl()\n",
    "dataset = d['data']\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have access to all the attributs and methods of the [dataframe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) object. For instance, we can easily print the number of rows in our dataframe which correspond to the number of articles in our corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = dataset.shape[0]\n",
    "print('There are ' + str(n) + ' articles in the dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Searching by metadata\n",
    "\n",
    "Now that the data from the XML-TEI files are loaded into a python dataframe, we can select groups of articles based on the article metadata that was originally stored in the TEI header.\n",
    "\n",
    "For instance, we can select articles based on their classification in the *Encyclopédie*. (There are actually a few different ways that the ARTFL *Encyclopédie* articles have been classified. In this notebook we will be using the `normclass` field, which normalizes classifications given at time of publication that had many spelling variants. In the cell below, we have hand selected all the `normclass` combinations that include Geography as well as Geography on its own.)\n",
    "\n",
    "If we want all articles classified as 'Geography' we can make the request as follows (the output is stored as a new data frame `df_geo`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normclassGEO = ['Géographie', 'Géographie moderne',\n",
    "                 'Géographie ancienne', 'Géographie moderne | Géographie ancienne',\n",
    "                 'Géographie ancienne | Géographie moderne', 'Géographie sacrée', 'Géographie sainte',\n",
    "                 'Géographie | Histoire ancienne', 'Géographie historique', 'Géographie | Histoire',\n",
    "                 'Histoire | Géographie', 'Géographie | Histoire naturelle', 'Géographie | Mythologie',\n",
    "                 'Géographie ancienne | Mythologie', 'Histoire moderne | Géographie',\n",
    "                 'Géographie ancienne | Géographie sainte', 'Géographie ancienne | Géographie sacrée',\n",
    "                 'Géographie sacrée | Géographie ancienne', 'Géographie du moyen âge', 'Géographie des Arabes',\n",
    "                 'Géographie | Commerce', 'Histoire | Géographie ancienne',\n",
    "                 'Géographie | Histoire ancienne | Histoire moderne', 'Géographie ancienne | Littérature | Histoire',\n",
    "                 'Histoire naturelle | Géographie', 'Géographie | Histoire ancienne | Mythologie',\n",
    "                 'Géographie moderne | Commerce', 'Géographie ancienne | Géographie antique',\n",
    "                 'Géographie moderne | Histoire', 'Géographie | Histoire monastique',\n",
    "                 'Géographie ancienne | Géographie moderne | Mythologie', 'Géographie ancienne | Histoire',\n",
    "                 'Géographie ancienne | Littérature | Mythologie', 'Géographie ancienne | Médailles'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Query the dataframe for all articles matching one of the class in our list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo = dataset.loc[dataset['normClass'].isin(normclassGEO)]\n",
    "df_geo.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are ' + str(df_geo.shape[0]) + ' geography articles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query based on any value in the dataframe (e.g. article metadata). For instance, we can query all the articles written by a specific author:\n",
    "\n",
    "* Count article for a single named author (Jaucourt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 'Jaucourt'\n",
    "n = df_geo.loc[dataset['author'] == val].shape[0]\n",
    "print(str(n) + ' were written by '+ val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily show the number of articles per author:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo.groupby(['author'])[\"filename\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to show the value of one column in our dataframe for a specific row (i.e., by article) based on its name. For instance, if we want to know who wrote the article about Lyon or if we want to see its content, we make these requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[dataset['head'] == 'FRONTIGNAN'].author.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Searching by text \n",
    "\n",
    "It is also possible to display and search the full text content of the articles stored in the dataframe. \n",
    "\n",
    "* Show full text for a specific article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[dataset['head'] == 'FRONTIGNAN'].text.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform a **keyword search** over the text content of all articles:\n",
    "\n",
    "* Select articles that contains 'france':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search corpus by keyword (val)\n",
    "\n",
    "val = 'france'\n",
    "df_2 = dataset[dataset['text'].str.contains(val, case=False)]\n",
    "print(str(df_2.shape[0]) + ' articles contain the word \\''+ val + '\\'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to search by **phrases**. The expression \"ville de\" is commonly used in the *Encyclopédie* to define the country or region of a place. Searching by this phrase gives us a sense of the broader geographical coverage of the corpus. \n",
    "\n",
    "Here we extract all articles that contain the expression 'ville de':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset['text'].str.contains(\"ville de\", case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can try a thematic search, for instance about 'esclavage' (slavery): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset['text'].str.contains(\"esclavage\", case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "asi5amjhkxKA"
   },
   "source": [
    "## 2. The NLP pipeline: Perdido Geoparser\n",
    "\n",
    "\n",
    "In Natural Language Processing (NLP), the main first steps before processing text content consist in tokenizing sentences and words and assigning to each word its grammatical category (Part-of-Speech). \n",
    "\n",
    "This allows the construction of more complex rules or queries compared to a simple keyword search. E.g. we would know that \"city\" is a noun, and we can perform a search for all nouns in the corpus.\n",
    "\n",
    "\n",
    "These preprocessing steps are language dependent, and therefore we have to choose the right tool according to the language, style and period of our documents. This is a major difficulty when dealing with historical or ancient texts. For instance, for French it is difficult to find a POS tagger for pre-20th century French as major well known taggers are trained on contemporary corpora.\n",
    "\n",
    "> McDonough, K., Moncla, L., & van de Camp, M. (2019). Named entity recognition goes to old regime France: geographic text analysis for early modern French corpora. International Journal of Geographical Information Science, 33, 2498–2522.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nTcr95AokxKh"
   },
   "source": [
    "### 2.1 Perdido Geoparser\n",
    "\n",
    "\n",
    "The `Perdido` geoparser uses [Treetagger](https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/) for part-of-speech tagging. \n",
    "\n",
    "\n",
    "The geotagging step of `Perdido` is perform using a cascade of finite-state transducers defining specific patterns for NER and identification of geographic information (spatial relations, etc.). \n",
    "> Mauro Gaio and Ludovic Moncla (2019). “Geoparsing and geocoding places in a dynamic space context.“ In The Semantics of Dynamic Space in French: Descriptive, experimental and formal studies on motion expression, 66, 353.\n",
    "\n",
    "Geoparsing in the digital humanities began with projects analyzing modern English-language corpora. But now, many researchers are developing projects for automatically identifying and geolocating places named in texts of many languages. \n",
    "\n",
    "Here we highlight the difficulties of extracting and mapping geographical information from historical French texts. In addition to language-related problems which impact the quality of tokenization, POS tagging, and NER, geocoding presents its own challenges. Once place names have been identifed in a text, correctly associating geographical coordinates with that place is a challenge. **Gazetteers** are knowledge bases that help researchers link place names with information about place, including its location. \n",
    "\n",
    "For our custom version of the `Perdido` Geoparser, the geocoding task uses a simple gazetteer lookup method. Several gazetteers can be used:\n",
    " - Nominatim (ie, OpenStreetMap) by default, \n",
    " - Geonames, \n",
    " - World Historical Gazetteer, \n",
    " - Pleiades\n",
    "\n",
    "Like using the most appropriate POS tagger, finding the best gazetteer for your corpus can be challenging. Luckily, for the ancient world, there are some excellent options. Here, you will also be able to test the [Pleiades gazetteer](https://pleiades.stoa.org/) and compare the results with the other contemporary gazetteers.\n",
    "\n",
    "\n",
    "The PERDIDO Geoparser returns XML-TEI. The `<name>` element refers to named entities (proper nouns) and the type attribute indicates its class (place, person, etc.). The `<rs>` element refers to extended named entities (e.g. ville d'Egypte). The `<location>` element indicates that geographic coordinates were found during geocoding.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Getting started with `Perdido`\n",
    "\n",
    "* Get the content from one article from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = dataset.loc[dataset['head'] == 'FRONTIGNAN'].text.item()\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instanciate a Geoparser object from the `Perdido` library. Specify that we are working with the *Encyclopédie* version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoparser = Geoparser(version=\"Encyclopedie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now you can use this geoparser for geoparsing text content. Let's try with the `content`variable that we declare before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = geoparser(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geoparser return a `Perdido`object. This object has several attributes and methods. We'll now see some of them.\n",
    "\n",
    "* Accessing the XML-TEI result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.tei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Accessing the geojson results generate during the geocoding phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transform the Perdido object into a dataframe (only some of the attributes are kept):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = doc.to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Save the results in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_xml('FRONTIGNAN-perdido.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_geojson('FRONTIGNAN-perdido.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_csv('FRONTIGNAN-perdido.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Display named entities\n",
    "\n",
    "Often, it is useful to vizualize the output in sentence form. The `spacy` library provides a useful tool for this: `displacy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc.to_spacy_doc(), style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc.to_spacy_doc(), style=\"span\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B7bw9rWGkxKx"
   },
   "source": [
    "#### 2.1.4 Mapping place names\n",
    "\n",
    "\n",
    "For many projects, it is important to view the results of geoparsing on a map. Here, we can see the results plotted on a map. But remember, these are only the results for which coordinates could be found. Results that could not be matched to records in the gazetteer will not be mapped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ay5XDTM1kxKy",
    "outputId": "93df6728-dd7e-40c7-c2c5-fae62699a7c0"
   },
   "outputs": [],
   "source": [
    "doc.get_folium_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Another example\n",
    "\n",
    "https://artflsrv03.uchicago.edu/philologic4/encyclopedie1117/navigate/7/2046/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = dataset.loc[dataset['head'] == 'GESSORIACUM'].text.item()\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = geoparser(content)\n",
    "displacy.render(doc.to_spacy_doc(), style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparison to other NER tools\n",
    "\n",
    "`Perdido` is a custom geoparsing library for French language documents. How does it compare to other state-of-the-art libraries?\n",
    "\n",
    "### 3.1 SpaCy\n",
    "\n",
    "[SpaCy](https://spacy.io/) is a commonly-used NLP library that supports documents in many languages. `SpaCy` uses Machine Learning to perform NER (versus being a rule-based system)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Install the `spaCy` french pre-trained language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import the `spaCy` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the `spaCy` french pre-trained language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_parser = spacy.load('fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the NER pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = spacy_parser(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Display the named entities with `displaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style=\"ent\", jupyter=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Stanza\n",
    "\n",
    "[Stanza](https://stanfordnlp.github.io/stanza/) is another NLP ML library developed by Stanford that is designed to work across many languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import the `Stanza` library and download the pre-trained french language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "# This can take a while depending on your internet connection (fr model is 572M)\n",
    "stanza.download('fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Declare the NER pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza_parser = stanza.Pipeline(lang='fr', processors='tokenize,ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the NER pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = stanza_parser(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the named entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing `Perdido`, `SpaCy`, and `Stanza` outputs, even for just 1-2 articles from our corpus, allows us to see common errors. One library might excel at identifying people, but struggle with complex place names. Another is better at capturing places named within phrases, but mixes up people and places. It is important to test multiple geoparsers for your corpus, and to understand how they can be adapted, in order to get the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Processing several documents at once\n",
    "\n",
    "Usually, we want to process a sample of documents, not just one. \n",
    "\n",
    "As the process can be time consuming we will first select a small sample from our dataset to show how it works.\n",
    "\n",
    "* We can use the [sample()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) method from the pandas library to select randomly a small amount of documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = dataset.sample(4)\n",
    "df_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Then, we keep only the text content of those documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = df_sampled.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`geoparser` can parse a `string`, a `list` of string or a `pandas.Series`.\n",
    "When the argument is a `list` or a `pandas.series`, the geoparser returns a `PerdidoCollection` object, while when it is a `string` it returns a `Perdido` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = geoparser(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print('-----')\n",
    "    displacy.render(doc.to_spacy_doc(), style=\"ent\", jupyter=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explore *Encyclopédie* geoparsed example dataset\n",
    "\n",
    "Now, let's work with the same sample of articles (all of volume 7), but already processed in Perdido. Below, you can select a subsample from this dataset based on a keyword search, and then make a map of those results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the dataset from the library using the `load_edda_perdido()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove this cell\n",
    "from perdido.geoparser import Geoparser\n",
    "from perdido.datasets import load_edda_artfl, load_edda_perdido\n",
    "\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_edda_perdido('pleiades')\n",
    "dataset = d['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, doc in enumerate(dataset):\n",
    "    print(dataset.metadata[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>volume</th>\n",
       "      <th>number</th>\n",
       "      <th>head</th>\n",
       "      <th>normClass</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>#_places</th>\n",
       "      <th>#_person</th>\n",
       "      <th>#_event</th>\n",
       "      <th>#_date</th>\n",
       "      <th>#_misc</th>\n",
       "      <th>#_locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>volume07-1099.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>1099</td>\n",
       "      <td>Funérailles des Grecs</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>unsigned</td>\n",
       "      <td>Funérailles des Grecs. Nous passons aux funéra...</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>volume07-1106.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>1106</td>\n",
       "      <td>Funérailles des Misilimakinaks</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>Jaucourt</td>\n",
       "      <td>Funérailles des Misilimakinaks. Il y a d'autre...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>volume07-1112.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>1112</td>\n",
       "      <td>FUNESTE</td>\n",
       "      <td>Grammaire</td>\n",
       "      <td>Diderot</td>\n",
       "      <td>* FUNESTE, adj. (Gramm.) qui porte malheur ; c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>volume07-1175.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>1175</td>\n",
       "      <td>Fusée</td>\n",
       "      <td>Manège | Maréchallerie</td>\n",
       "      <td>unsigned</td>\n",
       "      <td>Fusée, (Manége, Maréchall.) nous appellons de ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>volume07-1258.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>1258</td>\n",
       "      <td>GAGE</td>\n",
       "      <td>Jurisprudence</td>\n",
       "      <td>Boucher d'Argis</td>\n",
       "      <td>GAGE, pignus, s. m. (Jurisprud.) est un effet ...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename volume number                            head  \\\n",
       "0  volume07-1099.tei     07   1099           Funérailles des Grecs   \n",
       "1  volume07-1106.tei     07   1106  Funérailles des Misilimakinaks   \n",
       "2  volume07-1112.tei     07   1112                         FUNESTE   \n",
       "3  volume07-1175.tei     07   1175                           Fusée   \n",
       "4  volume07-1258.tei     07   1258                            GAGE   \n",
       "\n",
       "                normClass           author  \\\n",
       "0            unclassified         unsigned   \n",
       "1            unclassified         Jaucourt   \n",
       "2               Grammaire          Diderot   \n",
       "3  Manège | Maréchallerie         unsigned   \n",
       "4           Jurisprudence  Boucher d'Argis   \n",
       "\n",
       "                                                text  #_places  #_person  \\\n",
       "0  Funérailles des Grecs. Nous passons aux funéra...         5        14   \n",
       "1  Funérailles des Misilimakinaks. Il y a d'autre...         0         0   \n",
       "2  * FUNESTE, adj. (Gramm.) qui porte malheur ; c...         0         0   \n",
       "3  Fusée, (Manége, Maréchall.) nous appellons de ...         0         0   \n",
       "4  GAGE, pignus, s. m. (Jurisprud.) est un effet ...         5         8   \n",
       "\n",
       "   #_event  #_date  #_misc  #_locations  \n",
       "0        0       0       1            0  \n",
       "1        0       0       0            0  \n",
       "2        0       0       1            0  \n",
       "3        0       0       0            0  \n",
       "4        0       5       1            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>volume</th>\n",
       "      <th>number</th>\n",
       "      <th>head</th>\n",
       "      <th>normClass</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>#_places</th>\n",
       "      <th>#_person</th>\n",
       "      <th>#_event</th>\n",
       "      <th>#_date</th>\n",
       "      <th>#_misc</th>\n",
       "      <th>#_locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>volume07-1258.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>1258</td>\n",
       "      <td>GAGE</td>\n",
       "      <td>Jurisprudence</td>\n",
       "      <td>Boucher d'Argis</td>\n",
       "      <td>GAGE, pignus, s. m. (Jurisprud.) est un effet ...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>volume07-1808.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>1808</td>\n",
       "      <td>GELÉE</td>\n",
       "      <td>Physique</td>\n",
       "      <td>Ratte</td>\n",
       "      <td>GELÉE, s. f. (Physique.) froid par lequel l'ea...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>volume07-1890.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>1890</td>\n",
       "      <td>GENÈVE</td>\n",
       "      <td>Histoire | Politique</td>\n",
       "      <td>d'Alembert</td>\n",
       "      <td>GENÈVE, (Hist. &amp; Politiq.) Cette ville est sit...</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>volume07-2396.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>2396</td>\n",
       "      <td>GORDIEN (Noeud)</td>\n",
       "      <td>Littérature</td>\n",
       "      <td>Jaucourt</td>\n",
       "      <td>GORDIEN (Noeud), s. m. (Littérat.) noeud du ch...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>volume07-2802.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>2802</td>\n",
       "      <td>Grecs  (philosophie des)</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>Diderot</td>\n",
       "      <td>* Grecs (philosophie des). Je tirerai la divis...</td>\n",
       "      <td>53</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>volume07-1971.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>1971</td>\n",
       "      <td>Géographie physique</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>Desmarest</td>\n",
       "      <td>Géographie physique, est la description raison...</td>\n",
       "      <td>139</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>volume07-3141.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>3141</td>\n",
       "      <td>GUAXACA</td>\n",
       "      <td>Géographie</td>\n",
       "      <td>Jaucourt</td>\n",
       "      <td>GUAXACA, (Géogr.) province de l'Amerique septe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>volume07-1298.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>1298</td>\n",
       "      <td>Gageure</td>\n",
       "      <td>Jurisprudence</td>\n",
       "      <td>Boucher d'Argis</td>\n",
       "      <td>Gageure, (Jurisprud.) est une convention sur u...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>volume07-2168.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>2168</td>\n",
       "      <td>Glace</td>\n",
       "      <td>Médecine</td>\n",
       "      <td>unsigned</td>\n",
       "      <td>Glace, (Medecine.) Il y a différentes observat...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>volume07-2520.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>2520</td>\n",
       "      <td>Gout</td>\n",
       "      <td>Grammaire | Littérature | Philosophie</td>\n",
       "      <td>Voltaire &amp; Montesquieu &amp; Diderot &amp; d'Alembert</td>\n",
       "      <td>Gout, (Gramm. Litterat. &amp; Philos.) On a vû dan...</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename volume number                      head  \\\n",
       "0   volume07-1258.tei     07   1258                      GAGE   \n",
       "1   volume07-1808.tei     07   1808                     GELÉE   \n",
       "2   volume07-1890.tei     07   1890                    GENÈVE   \n",
       "3   volume07-2396.tei     07   2396           GORDIEN (Noeud)   \n",
       "4   volume07-2802.tei     07   2802  Grecs  (philosophie des)   \n",
       "..                ...    ...    ...                       ...   \n",
       "67  volume07-1971.tei     07   1971       Géographie physique   \n",
       "68  volume07-3141.tei     07   3141                   GUAXACA   \n",
       "69  volume07-1298.tei     07   1298                   Gageure   \n",
       "70  volume07-2168.tei     07   2168                     Glace   \n",
       "71  volume07-2520.tei     07   2520                      Gout   \n",
       "\n",
       "                                normClass  \\\n",
       "0                           Jurisprudence   \n",
       "1                                Physique   \n",
       "2                    Histoire | Politique   \n",
       "3                             Littérature   \n",
       "4                            unclassified   \n",
       "..                                    ...   \n",
       "67                           unclassified   \n",
       "68                             Géographie   \n",
       "69                          Jurisprudence   \n",
       "70                               Médecine   \n",
       "71  Grammaire | Littérature | Philosophie   \n",
       "\n",
       "                                           author  \\\n",
       "0                                 Boucher d'Argis   \n",
       "1                                           Ratte   \n",
       "2                                      d'Alembert   \n",
       "3                                        Jaucourt   \n",
       "4                                         Diderot   \n",
       "..                                            ...   \n",
       "67                                      Desmarest   \n",
       "68                                       Jaucourt   \n",
       "69                                Boucher d'Argis   \n",
       "70                                       unsigned   \n",
       "71  Voltaire & Montesquieu & Diderot & d'Alembert   \n",
       "\n",
       "                                                 text  #_places  #_person  \\\n",
       "0   GAGE, pignus, s. m. (Jurisprud.) est un effet ...         5         8   \n",
       "1   GELÉE, s. f. (Physique.) froid par lequel l'ea...        13        11   \n",
       "2   GENÈVE, (Hist. & Politiq.) Cette ville est sit...        27        21   \n",
       "3   GORDIEN (Noeud), s. m. (Littérat.) noeud du ch...         1         5   \n",
       "4   * Grecs (philosophie des). Je tirerai la divis...        53       100   \n",
       "..                                                ...       ...       ...   \n",
       "67  Géographie physique, est la description raison...       139         7   \n",
       "68  GUAXACA, (Géogr.) province de l'Amerique septe...         1         0   \n",
       "69  Gageure, (Jurisprud.) est une convention sur u...         4        12   \n",
       "70  Glace, (Medecine.) Il y a différentes observat...         2         7   \n",
       "71  Gout, (Gramm. Litterat. & Philos.) On a vû dan...        11        29   \n",
       "\n",
       "    #_event  #_date  #_misc  #_locations  \n",
       "0         0       5       1            0  \n",
       "1         0       0       2            0  \n",
       "2         0       8       5            0  \n",
       "3         0       0       1            0  \n",
       "4         0       0      26            0  \n",
       "..      ...     ...     ...          ...  \n",
       "67        0       0       1            0  \n",
       "68        0       0       0            0  \n",
       "69        0       3       6            0  \n",
       "70        0       1       0            0  \n",
       "71        0       1       1            0  \n",
       "\n",
       "[72 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keyword search\n",
    "collection = dataset.keyword_search(keyword='rome')\n",
    "collection.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>volume</th>\n",
       "      <th>number</th>\n",
       "      <th>head</th>\n",
       "      <th>normClass</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>#_places</th>\n",
       "      <th>#_person</th>\n",
       "      <th>#_event</th>\n",
       "      <th>#_date</th>\n",
       "      <th>#_misc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>volume07-1890.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>1890</td>\n",
       "      <td>GENÈVE</td>\n",
       "      <td>Histoire | Politique</td>\n",
       "      <td>d'Alembert</td>\n",
       "      <td>GENÈVE, (Hist. &amp; Politiq.) Cette ville est sit...</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename volume number    head             normClass      author  \\\n",
       "0  volume07-1890.tei     07   1890  GENÈVE  Histoire | Politique  d'Alembert   \n",
       "\n",
       "                                                text  #_places  #_person  \\\n",
       "0  GENÈVE, (Hist. & Politiq.) Cette ville est sit...        27        21   \n",
       "\n",
       "   #_event  #_date  #_misc  \n",
       "0        0       8       5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter by metadata\n",
    "collection = dataset.filter_equal(column='head', value='GENÈVE')\n",
    "collection.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>volume</th>\n",
       "      <th>number</th>\n",
       "      <th>head</th>\n",
       "      <th>normClass</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>#_places</th>\n",
       "      <th>#_person</th>\n",
       "      <th>#_event</th>\n",
       "      <th>#_date</th>\n",
       "      <th>#_misc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>volume07-1258.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>1258</td>\n",
       "      <td>GAGE</td>\n",
       "      <td>Jurisprudence</td>\n",
       "      <td>Boucher d'Argis</td>\n",
       "      <td>GAGE, pignus, s. m. (Jurisprud.) est un effet ...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>volume07-1890.tei</td>\n",
       "      <td>07</td>\n",
       "      <td>1890</td>\n",
       "      <td>GENÈVE</td>\n",
       "      <td>Histoire | Politique</td>\n",
       "      <td>d'Alembert</td>\n",
       "      <td>GENÈVE, (Hist. &amp; Politiq.) Cette ville est sit...</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename volume number    head             normClass  \\\n",
       "0  volume07-1258.tei     07   1258    GAGE         Jurisprudence   \n",
       "1  volume07-1890.tei     07   1890  GENÈVE  Histoire | Politique   \n",
       "\n",
       "            author                                               text  \\\n",
       "0  Boucher d'Argis  GAGE, pignus, s. m. (Jurisprud.) est un effet ...   \n",
       "1       d'Alembert  GENÈVE, (Hist. & Politiq.) Cette ville est sit...   \n",
       "\n",
       "   #_places  #_person  #_event  #_date  #_misc  \n",
       "0         5         8        0       5       1  \n",
       "1        27        21        0       8       5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter by metadata\n",
    "collection = dataset.filter_in(column='head', values=['GENÈVE', 'GAGE'])\n",
    "collection.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by metadata\n",
    "collection = dataset.filter_equal(column='#_locations', value=0)\n",
    "collection.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only docs that contain place names\n",
    "docs_with_places = dataset.contains('place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only docs that contain locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map a collection of documents\n",
    "m = collection.get_folium_map()\n",
    "if m is None:\n",
    "    print('No location found!')\n",
    "else:\n",
    "    m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot number of entities per documents\n",
    "\n",
    "# get the document with the maximum places...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Toponym disambiguation using network analysis\n",
    "\n",
    "In our work, we use this methodoly for constructing a network based on the citation of \"géographie\" articles between them.\n",
    "We proposed to use network analysis measures to establish an approximate location, defined by qualitative relations, for each named toponym in EDDA. Throwing a list of decontextualized toponyms at an external resource like Geonames is risky. We therefore hypothesize that defining meaningful links between places can provide essentialinformation to improve disambiguation (and potentially replace resolution as the end goal). We establish connections between places based on the citation of “headword” toponyms (those that appearas headwords of entries) in other EDDA entries.\n",
    "\n",
    ">Moncla, L., McDonough, K., Vigier, D., Joliveau, T., & Brenon, A. (2019). Toponym disambiguation in historical documents using network analysis of qualitative relationships. Proceedings of the 3rd ACM SIGSPATIAL International Workshop on Geospatial Humanities, 1–4. Chicago, IL, USA.\n",
    "\n",
    "This method draws on relations in the corpus of EDDA articles, which improves disambiguation at a later stage with an external resource. We suggest the network as an alternative to geospatial representation, a useful proxy when no historical gazetteer exists for the source material's period. Our first experiments have shown that this approach goes beyond a simple text analysis and is able to find relations between toponyms that are not co-occurring in the same documents. Network relations are also usefully compared with disambiguated toponyms to evaluate geographical coverage, and the ways that geographical discourse is expressed, in historical texts.\n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <img src=\"img/labels_indegree2.png\" width =\"500px\"> </td>\n",
    "    <td> <img src=\"img/nodes_betweenness+class2.png\" width =\"500px\" > </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Node and label size indicate in-degree centrality</td>\n",
    "    <td>Node size indicates betweenness centrality<br/> \n",
    "        colors refer to geographic feature types <br/> \n",
    "        (city: red, hydronym: blue, country: green, mountain: brown, unclassified: grey)</td>\n",
    "  </tr>\n",
    "</table> \n",
    "\n",
    "\n",
    "\n",
    "We also made somse preliminary tests by assigning geographic coordinates found in our French wikiGazetteer to each node (headword). We have only 2535 nodes with coordinates over the 13734 nodes. \n",
    "\n",
    "Our first experiment is shown below. Colors identify clusters of nodes computed with the [modularity measure](https://en.wikipedia.org/wiki/Modularity_(networks)) implemented on Gephy.\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"img/geocodingEDDA1.png\" width =\"500\"> </td>\n",
    "<td> <img src=\"img/geocodingEDDA_network.png\" width =\"500\" > </td>\n",
    "</tr></table> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mDgWiH2-kxMB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Geoparsing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sunoikisis-py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0706207376f2dbae316cdd2388509d85cbd8c808bf8c3cd698a4e4eda55d0086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
